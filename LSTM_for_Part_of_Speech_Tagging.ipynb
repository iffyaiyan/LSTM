{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM for Part-of-Speech Tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvhsJqqfiRzriI3mw9BY8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iffyaiyan/LSTM/blob/main/LSTM_for_Part_of_Speech_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHsCF-GLM7V"
      },
      "source": [
        "# importing the necessary libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEGmuV3ILiEX"
      },
      "source": [
        "training_data = [\n",
        "    (\"The cat ate the cheese\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"She read that book\".lower().split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"The dog loves art\".lower().split(), [\"DET\", \"NN\", \"V\", \"NN\"]),\n",
        "    (\"The elephant answers the phone\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "\n",
        "# Dictionay to map word to indices\n",
        "word2idx = {}\n",
        "for sent, tags in training_data:\n",
        "  for word in sent:\n",
        "    if word not in word2idx:\n",
        "      word2idx[word] = len(word2idx)\n",
        "\n",
        "# Create a dictionary that maps tags to indices\n",
        "tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR9X4BDlMng8",
        "outputId": "3bfa4fcd-4fa0-4037-c460-773087a898c7"
      },
      "source": [
        "#Printing the dictionart created\n",
        "print(word2idx)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 0, 'cat': 1, 'ate': 2, 'cheese': 3, 'she': 4, 'read': 5, 'that': 6, 'book': 7, 'dog': 8, 'loves': 9, 'art': 10, 'elephant': 11, 'answers': 12, 'phone': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrVtiQhpM7jk"
      },
      "source": [
        "We can see each unique word has unique index assosciated with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQvbAXDM1So"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Creating a helper function to convert a sequence of words to a Tensor of numerical values\n",
        "\n",
        "def prepare_sequence(seq, to_idx):\n",
        "  '''\n",
        "    seq: sequence of words\n",
        "    to_idx: dictionary to index \n",
        "  '''\n",
        "  idxs = [to_idx[w] for w in seq]\n",
        "  idxs = np.array(idxs)\n",
        "  return torch.from_numpy(idxs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSOyt2-dOBhj",
        "outputId": "e83290a3-cfbd-45f0-93c5-e6bdd97a4992"
      },
      "source": [
        "# Lets use the above defined function\n",
        "\n",
        "example = prepare_sequence(\"She ate the Cheese cat loves the\".lower().split(), word2idx)\n",
        "print(example)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4, 2, 0, 3, 1, 9, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbiw6tCOPDeP"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        \n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        \n",
        "    def init_hidden(self):\n",
        "\n",
        "        return (torch.zeros(1, 1, self.hidden_dim),\n",
        "                torch.zeros(1, 1, self.hidden_dim))\n",
        "    \n",
        "    def forward(self, sentence):\n",
        "\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
        "\n",
        "        tag_outputs = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_outputs, dim=1)\n",
        "        \n",
        "        return tag_scores"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWL8xAaNXguB"
      },
      "source": [
        "#Define how the model trains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5zPB-LwXMqh"
      },
      "source": [
        "\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx))\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvibVY2bX93T",
        "outputId": "b28f285a-c466-49d4-ca8d-878f0df8211d"
      },
      "source": [
        "test_sentence = \"Elephant loves the book cheese\".lower().split()\n",
        "\n",
        "inputs = prepare_sequence(test_sentence, word2idx)\n",
        "inputs = inputs\n",
        "tag_scores = model(inputs)\n",
        "print(tag_scores)\n",
        "_, predicted_tags = torch.max(tag_scores, 1)\n",
        "print('\\n')\n",
        "print('Predicted tags: \\n', predicted_tags)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.2237, -1.2054, -0.9008],\n",
            "        [-1.2353, -1.2004, -0.8961],\n",
            "        [-1.1850, -1.1714, -0.9563],\n",
            "        [-1.3922, -1.0608, -0.9031],\n",
            "        [-1.3229, -1.0724, -0.9379]], grad_fn=<LogSoftmaxBackward>)\n",
            "\n",
            "\n",
            "Predicted tags: \n",
            " tensor([2, 2, 2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RN4qMfGaYNz"
      },
      "source": [
        "#Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il6NvEyYZxC0",
        "outputId": "690d45a7-7069-481a-e802-2e2c25474dab"
      },
      "source": [
        "n_epochs = 300\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  epoch_loss = 0.0\n",
        "\n",
        "  for sentence, tags in training_data:\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    model.hidden = model.init_hidden()\n",
        "\n",
        "    sentence_in = prepare_sequence(sentence, word2idx)\n",
        "    targets = prepare_sequence(tags, tag2idx)\n",
        "\n",
        "    tag_scores = model(sentence_in)\n",
        "\n",
        "    loss = loss_function(tag_scores, targets)\n",
        "    epoch_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  if(epoch%20 == 19):\n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(training_data)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20, loss: 0.96931\n",
            "Epoch: 40, loss: 0.80035\n",
            "Epoch: 60, loss: 0.61774\n",
            "Epoch: 80, loss: 0.51589\n",
            "Epoch: 100, loss: 0.45520\n",
            "Epoch: 120, loss: 0.38913\n",
            "Epoch: 140, loss: 0.30337\n",
            "Epoch: 160, loss: 0.20163\n",
            "Epoch: 180, loss: 0.11180\n",
            "Epoch: 200, loss: 0.06761\n",
            "Epoch: 220, loss: 0.04700\n",
            "Epoch: 240, loss: 0.03563\n",
            "Epoch: 260, loss: 0.02850\n",
            "Epoch: 280, loss: 0.02364\n",
            "Epoch: 300, loss: 0.02011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rohbXVSqbWjt",
        "outputId": "98b92c14-4476-483a-847e-678ceace3022"
      },
      "source": [
        "test_sentence = \"Elephant loves the book cheese\".lower().split()\n",
        "\n",
        "inputs = prepare_sequence(test_sentence, word2idx)\n",
        "inputs = inputs\n",
        "tag_scores = model(inputs)\n",
        "print(tag_scores)\n",
        "\n",
        "_, predicted_tags = torch.max(tag_scores, 1)\n",
        "print('\\n')\n",
        "print('Predicted tags: \\n', predicted_tags)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.5045e+00, -2.9505e+00, -6.5472e-02],\n",
            "        [-5.4710e+00, -3.7293e+00, -2.8623e-02],\n",
            "        [-8.6447e-03, -5.0243e+00, -6.1991e+00],\n",
            "        [-5.8634e+00, -6.1005e-03, -5.7321e+00],\n",
            "        [-4.8022e+00, -1.1387e-01, -2.3085e+00]], grad_fn=<LogSoftmaxBackward>)\n",
            "\n",
            "\n",
            "Predicted tags: \n",
            " tensor([2, 2, 0, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrS9aERccyBu"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}